{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kajaskramo/Documents/Programvareutvikling/Semester 2/DAT255/Project/255-Project/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.18.0\n",
      "Keras version: 3.8.0\n",
      "Numpy version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from datasets import Dataset, load_dataset\n",
    "import librosa\n",
    "from keras import layers, models\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"Numpy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 1.18G/1.18G [04:21<00:00, 4.49MB/s] \n",
      "Downloading data: 100%|██████████| 154M/154M [00:40<00:00, 3.84MB/s] \n",
      "Downloading data: 100%|██████████| 125M/125M [00:35<00:00, 3.50MB/s] \n",
      "Generating train split: 100%|██████████| 51093/51093 [00:10<00:00, 4957.12 examples/s]\n",
      "Generating validation split: 100%|██████████| 6799/6799 [00:01<00:00, 4800.66 examples/s]\n",
      "Generating test split: 100%|██████████| 3081/3081 [00:00<00:00, 4819.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file', 'audio', 'label', 'is_unknown', 'speaker_id', 'utterance_id'],\n",
      "        num_rows: 51093\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['file', 'audio', 'label', 'is_unknown', 'speaker_id', 'utterance_id'],\n",
      "        num_rows: 6799\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['file', 'audio', 'label', 'is_unknown', 'speaker_id', 'utterance_id'],\n",
      "        num_rows: 3081\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"google/speech_commands\", \"v0.01\")\n",
    "# Overview of the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check available devices\n",
    "print(\"Available devices:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  44%|████▍     | 22576/51093 [01:06<01:24, 337.26 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m     log_mel_spectogram = np.expand_dims(log_mel_spectogram, axis=-\u001b[32m1\u001b[39m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m'\u001b[39m: log_mel_spectogram}\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m train_dataset = \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_audio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m validation_dataset = dataset[\u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m].map(preprocess_audio)\n\u001b[32m     16\u001b[39m test_dataset = dataset[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m].map(preprocess_audio)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Programvareutvikling/Semester 2/DAT255/Project/255-Project/venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:562\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m self_format = {\n\u001b[32m    556\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    557\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    558\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    559\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    560\u001b[39m }\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m datasets: List[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Programvareutvikling/Semester 2/DAT255/Project/255-Project/venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3079\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[39m\n\u001b[32m   3073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3074\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[32m   3075\u001b[39m         unit=\u001b[33m\"\u001b[39m\u001b[33m examples\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3076\u001b[39m         total=pbar_total,\n\u001b[32m   3077\u001b[39m         desc=desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMap\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3078\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m3079\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Programvareutvikling/Semester 2/DAT255/Project/255-Project/venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3495\u001b[39m, in \u001b[36mDataset._map_single\u001b[39m\u001b[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[39m\n\u001b[32m   3493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[32m   3494\u001b[39m     _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Programvareutvikling/Semester 2/DAT255/Project/255-Project/venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3469\u001b[39m, in \u001b[36mDataset._map_single.<locals>.iter_outputs\u001b[39m\u001b[34m(shard_iterable)\u001b[39m\n\u001b[32m   3467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3468\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[32m-> \u001b[39m\u001b[32m3469\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Programvareutvikling/Semester 2/DAT255/Project/255-Project/venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3392\u001b[39m, in \u001b[36mDataset._map_single.<locals>.apply_function\u001b[39m\u001b[34m(pa_inputs, indices, offset)\u001b[39m\n\u001b[32m   3390\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[32m   3391\u001b[39m inputs, fn_args, additional_args, fn_kwargs = prepare_inputs(pa_inputs, indices, offset=offset)\n\u001b[32m-> \u001b[39m\u001b[32m3392\u001b[39m processed_inputs = \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mpreprocess_audio\u001b[39m\u001b[34m(set)\u001b[39m\n\u001b[32m      3\u001b[39m audio_array = \u001b[38;5;28mset\u001b[39m[\u001b[33m'\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33marray\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m sampling_rate = \u001b[38;5;28mset\u001b[39m[\u001b[33m'\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33msampling_rate\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m mel_spectogram = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43maudio_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m log_mel_spectogram = librosa.power_to_db(mel_spectogram)\n\u001b[32m     10\u001b[39m log_mel_spectogram = np.expand_dims(log_mel_spectogram, axis=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Programvareutvikling/Semester 2/DAT255/Project/255-Project/venv/lib/python3.12/site-packages/librosa/feature/spectral.py:2143\u001b[39m, in \u001b[36mmelspectrogram\u001b[39m\u001b[34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[39m\n\u001b[32m   2130\u001b[39m S, n_fft = _spectrogram(\n\u001b[32m   2131\u001b[39m     y=y,\n\u001b[32m   2132\u001b[39m     S=S,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2139\u001b[39m     pad_mode=pad_mode,\n\u001b[32m   2140\u001b[39m )\n\u001b[32m   2142\u001b[39m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2143\u001b[39m mel_basis = \u001b[43mfilters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2145\u001b[39m melspec: np.ndarray = np.einsum(\u001b[33m\"\u001b[39m\u001b[33m...ft,mf->...mt\u001b[39m\u001b[33m\"\u001b[39m, S, mel_basis, optimize=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Programvareutvikling/Semester 2/DAT255/Project/255-Project/venv/lib/python3.12/site-packages/librosa/filters.py:239\u001b[39m, in \u001b[36mmel\u001b[39m\u001b[34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[39m\n\u001b[32m    236\u001b[39m     upper = ramps[i + \u001b[32m2\u001b[39m] / fdiff[i + \u001b[32m1\u001b[39m]\n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# .. then intersect them with each other and zero\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     weights[i] = np.maximum(\u001b[32m0\u001b[39m, \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(norm, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m norm == \u001b[33m\"\u001b[39m\u001b[33mslaney\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    243\u001b[39m         \u001b[38;5;66;03m# Slaney-style mel is scaled to be approx constant energy per channel\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_audio(set):\n",
    "\n",
    "    audio_array = set['audio']['array']\n",
    "    sampling_rate = set['audio']['sampling_rate']\n",
    "\n",
    "    mel_spectogram = librosa.feature.melspectrogram(y=audio_array, sr=sampling_rate, n_mels=128)\n",
    "\n",
    "    log_mel_spectogram = librosa.power_to_db(mel_spectogram)\n",
    "\n",
    "    log_mel_spectogram = np.expand_dims(log_mel_spectogram, axis=-1)\n",
    "\n",
    "    return {'audio': log_mel_spectogram}\n",
    "\n",
    "train_dataset = dataset['train'].map(preprocess_audio)\n",
    "validation_dataset = dataset['validation'].map(preprocess_audio)\n",
    "test_dataset = dataset['test'].map(preprocess_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple CNN model\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(shape=(128, 32, 1)),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(12, activation='softmax') # Number of possible commands\n",
    "])\n",
    "\n",
    "# Compiling\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_generator(dataset):\n",
    "    for sample in dataset:\n",
    "        audio_features = sample['audio']\n",
    "        label = sample['label']\n",
    "        \n",
    "        # Convert audio_features to a numpy array (if it's not already)\n",
    "        audio_features = np.array(audio_features)\n",
    "        \n",
    "        # Ensure the audio features have the shape (128, 32, 1)\n",
    "        # Pad or truncate if necessary (this assumes the audio data is 2D, with shape (128, n_features, 1))\n",
    "        if audio_features.shape[1] < 32:\n",
    "            # Pad the sequence if it's shorter than expected\n",
    "            pad_width = 32 - audio_features.shape[1]\n",
    "            audio_features = np.pad(audio_features, ((0, 0), (0, pad_width), (0, 0)), mode='constant')\n",
    "        elif audio_features.shape[1] > 32:\n",
    "            # Truncate the sequence if it's longer than expected\n",
    "            audio_features = audio_features[:, :32, :]\n",
    "        \n",
    "        # Yield the audio features and label\n",
    "        yield audio_features, label\n",
    "\n",
    "def convert_to_tf_dataset(dataset):\n",
    "    # Create a TensorFlow Dataset from the generator\n",
    "    tf_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: audio_generator(dataset), \n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(128, 32, 1), dtype=tf.float32),  # The expected shape of the audio data\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int64)  # Adjust dtype according to your label type (e.g., tf.int64 for class labels)\n",
    "        )\n",
    "    )\n",
    "    return tf_dataset\n",
    "\n",
    "\n",
    "# Convert the train, validation, and test datasets\n",
    "train_tf_dataset = convert_to_tf_dataset(train_dataset)\n",
    "validation_tf_dataset = convert_to_tf_dataset(validation_dataset)\n",
    "test_tf_dataset = convert_to_tf_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting the model now!!!\")\n",
    "\n",
    "model.fit(\n",
    "    train_tf_dataset.batch(128),\n",
    "    epochs=10,  # Can be changed\n",
    "    validation_data=validation_tf_dataset.batch(128)\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_tf_dataset)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
